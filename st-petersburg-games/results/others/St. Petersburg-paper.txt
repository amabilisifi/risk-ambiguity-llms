Abstract
The St. Petersburg paradox, a classic problem in probability theory and economics, challenges the concept of expected value by presenting a game with a theoretically infinite expected payoff but a low probability of a large win. This paper analyzes how four distinct large language models—GPT-4o, GPT-4o-mini, GPT-4.1, and GPT-5—respond to this paradox across a range of entrance fees. The study found a clear distinction in decision-making: while all models initially relied on the game's infinite expected value to justify playing at low fees , they progressively incorporated practical, real-world constraints such as risk aversion and diminishing marginal utility of money as the entrance fee increased. Later-generation models, particularly GPT-5, demonstrated a more nuanced, human-like reasoning process, balancing theoretical principles with practical considerations.

1. Introduction
The St. Petersburg paradox centers on a game where a coin is flipped until it lands on heads. According to classical expected value theory, a rational agent should be willing to pay any finite amount to play this game. However, in reality, most people would not pay a substantial amount to play, highlighting the limitations of expected value theory and the relevance of concepts like utility and risk aversion. This study examines how different models navigate this conflict between theoretical rationality and practical reasoning.

2. Methodology
A simulation was conducted where four models—GPT-4o, GPT-4o-mini, GPT-4.1, and GPT-5—were prompted with the rules of the St. Petersburg game and a series of increasing entrance fees: $1, $2, $4, $8, $16, $32, $100, $1,000, $10,000, and $100,000. For each fee, the models provided a decision (Play or Pass) and a written justification. The data was collected and analyzed to assess the models' decisions and the underlying reasoning, with keyword co-occurrence analysis used to identify the conceptual anchors of their justifications.

3. Results and Analysis
The models' decisions consistently shifted from Play to Pass as the entrance fee increased, though the specific threshold for this shift varied among models. Low Fees ($1-$8): All models demonstrated a high probability of playing, citing the game's infinite expected value as the primary justification. For instance, GPT-4o and GPT-4o-mini consistently chose to play for fees up to $8. Mid-Range Fees ($16-$100): The models began to diverge. GPT-4o-mini and GPT-4o's probability of playing dropped sharply at the $32 fee. GPT-4.1 showed a similar, though slightly earlier, decline in its likelihood of playing. GPT-5 maintained a higher probability of playing at these fees, passing only at the $1000 and $10,000 marks, a more aggressive stance than the other models. High Fees ($1,000+): All models universally chose to Pass. The justifications at these levels focused on the extremely low probability of a large payout, the impracticality of achieving a return on the investment, and the outright risk of losing a significant sum.



Model	$1	$2	$4	$8	$16	$32	$100	$1,000	$10,000	$100,000
gpt-4.1	0.9	1.0	1.0	0.7	0.4	0.0	0.0	0.0	0.0	0.0
gpt-4o	1.0	1.0	1.0	1.0	0.9	0.2	0.0	0.0	0.0	0.0
gpt-4o-mini	1.0	1.0	1.0	0.9	0.9	0.2	0.2	0.0	0.0	0.0
gpt-5	1.0	1.0	1.0	0.8	0.7	0.6	0.6	0.1	0.0	0.1

The values represent the probability of playing at a given entrance fee. The justifications provided by the models revealed a shift in their reasoning as the fees increased. At low fees, their responses were dominated by keywords like "infinite" and "expected value", often directly quoting the mathematical formula for the expected value. As fees rose, the models increasingly incorporated keywords such as "risk", "rational", and "utility". This change indicates a transition from a purely mathematical framework to a more nuanced one that accounts for real-world constraints. While GPT-4o’s justifications were heavily dominated by the "infinity" argument, GPT-4.1 and GPT-5 integrated a broader range of concepts, including diminishing returns and risk, suggesting they are better at mimicking human-like reasoning in financial decision-making.

4. Conclusion
The analysis of the models' behavior in the St. Petersburg game highlights a key evolution in their reasoning capabilities. All models recognized the theoretical paradox, but their application of this knowledge was sensitive to the practical implications of the entrance fee. As the cost of the gamble increased, the models, especially newer versions, demonstrated an increasing reliance on real-world concepts like utility and risk, moving beyond the simple "infinite expected value" argument. This suggests that newer models are becoming more adept at complex, multi-faceted reasoning that incorporates both theoretical principles and practical constraints, a crucial step toward more sophisticated, human-like financial decision-making.
The St. Petersburg paradox is a classic problem in probability and economics that illustrates a conflict between a mathematically sound decision and a practically irrational one. The game involves flipping a coin until it lands on heads. The study involved simulating the game with four models: GPT-4o, GPT-4o-mini, GPT-4.1, and GPT-5. The models were prompted with the game's rules and a series of increasing entrance fees ($1, $2, $4, $8, $16, $32, $100, $1,000, $10,000, and $100,000). For each fee, the models provided a decision (Play or Pass) and a justification. This data was then analyzed to track their decision-making process and reasoning across different fee levels.

The models' decisions consistently shifted from Play at low fees to Pass at high fees.

Low Fees ($1 - $8): All models demonstrated a high probability of playing, largely due to the infinite expected value argument.

Mid-Range Fees ($16 - $100): The models' decisions began to diverge. GPT-4o and GPT-4o-mini showed a sharp decrease in the probability of playing, while GPT-5 maintained a higher likelihood of playing, passing only at much higher fees.

High Fees ($1,000+): All models universally chose to Pass, recognizing the extremely low probability of a large payout compared to the high risk of loss.

The models' justifications evolved as the entrance fee increased. At low fees, their reasoning was dominated by purely mathematical concepts like "infinite expected value." However, as the fees rose, their justifications increasingly incorporated practical, real-world constraints. Keywords such as "risk," "rational," "utility," and "diminishing returns" became more prevalent in their responses, indicating a shift from a theoretical framework to a more nuanced, human-like understanding of risk and value.

The analysis revealed a clear difference in the sophistication of reasoning across the models. While all models recognized the theoretical paradox, later-generation models demonstrated a more balanced approach.

GPT-4o: Tended to be more heavily anchored to the "infinite expected value" argument, even at higher fees, showing less nuanced reasoning compared to its successors.

GPT-4.1 and GPT-5: Integrated a broader range of concepts, including risk and utility, more readily than earlier models. GPT-5, in particular, displayed a more robust, human-like reasoning process, balancing theoretical principles with a practical understanding of risk and loss, making it more hesitant to play at high stakes.
