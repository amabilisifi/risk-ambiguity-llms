{
  "experiment_info": {
    "experiment_type": "token_estimation_with_averaging",
    "timestamp": "20250930_122404",
    "description": "Token usage estimation with averaging (5 trials per game using GPT-4o as representative model)",
    "models_tested": 1,
    "games_tested": 4,
    "trials_per_game": 5,
    "total_trials_attempted": 20,
    "successful_trials": 4,
    "note": "GPT-4o tested with 5 trials per game, results averaged. Token patterns similar across models."
  },
  "token_estimates": [
    {
      "game": "risk_game",
      "model": "gpt-4o",
      "input_tokens": 117,
      "output_tokens": 61,
      "total_tokens": 178,
      "success": true,
      "trials_run": 5,
      "note": "Averaged across 5 successful trials"
    },
    {
      "game": "ambiguity_game",
      "model": "gpt-4o",
      "input_tokens": 152,
      "output_tokens": 29,
      "total_tokens": 181,
      "success": true,
      "trials_run": 5,
      "note": "Averaged across 5 successful trials"
    },
    {
      "game": "st_petersburg_game",
      "model": "gpt-4o",
      "input_tokens": 327,
      "output_tokens": 10,
      "total_tokens": 337,
      "success": true,
      "trials_run": 5,
      "note": "Averaged across 5 successful trials"
    },
    {
      "game": "st_petersburg_justification",
      "model": "gpt-4o",
      "input_tokens": 143,
      "output_tokens": 85,
      "total_tokens": 228,
      "success": true,
      "trials_run": 5,
      "note": "Averaged across 5 successful trials"
    }
  ],
  "pricing_note": "Use these averaged token counts with your Azure OpenAI pricing. Multiply by actual call counts from llm_calls_report.txt."
}